# In-Contextual Gender Bias Suppression for Large Language Models
***
This repository hosts the code for our paper, [In-Contextual Gender Bias Suppression for Large Language Models](https://arxiv.org/abs/2309.07251).
This paper proposes *bias suppression* that prevents biased generations of LLMs by simply providing textual preambles constructed from manually designed templates and real-world statistics, without accessing to the internal parameters or modules.
