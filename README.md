# In-Contextual Gender Bias Suppression for Large Language Models

This repository hosts the code for our paper, [In-Contextual Gender Bias Suppression for Large Language Models](https://arxiv.org/abs/2309.07251).
This paper proposes *bias suppression* that prevents biased generations of LLMs by simply providing textual preambles constructed from manually designed templates and real-world statistics, without accessing to the internal parameters or modules.

## Getting Started
The notebooks we provide can be run on cloud platforms such as [Google Colab](https://colab.research.google.com/) or local machines. 
In addition, each must [apply](https://llama.meta.com/) to use Llama2 in order to execute code related to Llama2.

## Citation

```bibtex
@misc{oba2024incontextual,
      title={In-Contextual Gender Bias Suppression for Large Language Models}, 
      author={Daisuke Oba and Masahiro Kaneko and Danushka Bollegala},
      year={2024},
      eprint={2309.07251},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
